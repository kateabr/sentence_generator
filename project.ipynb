{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this project\n",
    "\n",
    "### Goal\n",
    "\n",
    "To develop an application that would generate syntactically correct sentences using a deterministic algorithm (as opposed to neural networks' ways of producing sentences).\n",
    "\n",
    "### What for?\n",
    "\n",
    "To see if it is possible to generate sentences in a fully hand-made way, using a finite algorithm that only needs a set of sentence-building rules and a list of words. The main difference of this approach is that once developed, rules can develop almost infinite complexity, which, in addition to a diverse enough dictionary, will make possible generation of completely grammatical sentences.\n",
    "\n",
    "### Plan of work\n",
    "\n",
    "#### Milestones\n",
    "\n",
    "* Loading and parsing a dictionary\n",
    "* Loading and parsing sentence-building rules\n",
    "* Generating sentences from dictionary and rules\n",
    "\n",
    "#### Secondary tasks\n",
    "\n",
    "* A markdown for easy parsing\n",
    "* Structure of rules\n",
    "* A list of word traits for all sorts of agreements\n",
    "* Listing possible sentence structures\n",
    "\n",
    "### Scheme of work\n",
    "\n",
    "1. Dictionary is loaded and parsed\n",
    "2. Rules are loaded and parsed\n",
    "3. A random sentence structure is chosen\n",
    "4. The sentence structure is split into phrase skeletons that comprise it\n",
    "5. Each phrase skeleton, starting with the leftmost, undergo the stages of internal and external (cross-phrase) agreement\n",
    "6. Each phrase skeleton is replaced with phrases of real words.\n",
    "7. Phrases are merged into a sentence.\n",
    "\n",
    "### Accomplishments\n",
    "\n",
    "The program successfully loads and parses dictionaries and rules, and successfully produces sentences of 2 different types with more than 3 possible structures each.\n",
    "\n",
    "### Future plans\n",
    "\n",
    "Adding more rules and words, introducing new parts of speech. Possibly, enhancing the program to yield more than one sentences, connected with each other. Maybe, someday, adding stress and syllable count into traits with production of rhymes in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General preparations\n",
    "\n",
    "Importing required components, defining types.\n",
    "\n",
    "* WordRecord = an entry that contains information about words such as default form, inflection/conjugation data and word traits (Animacy, Gender etc.).\n",
    "* * Nesting principle: Quantity > Person > Gender > Case > Animacy __(1)__ (If a trait is present, then it is addressed before the ones that follow it)\n",
    "\n",
    "\n",
    "* Phrase word record = an entry that contains requirements for a word in a phrase, so that the resulting phrase is syntactically grammatical.\n",
    "* * Nesting principle: see __(1)__\n",
    "\n",
    "\n",
    "* Traits present so far: Animacy, Gender, Tense, Perfectivity, Quantity, Case, PhraseHead, Person, Transitivity\n",
    "\n",
    "* Notes:\n",
    "> __Animacy__: Animate/Inanimate -- note that it is grammatical animacy, the one that defines the form of a preceding adjective's accusative case.\n",
    "> __PhraseHead__: Head/Slave -- used to mark a phrase's leading word in terms of agreement.\n",
    "\n",
    "\n",
    "* startingNT = a non-terminal symbol that is used for choosing sentence structure; right now there can be only one of them -- \"S\".\n",
    "\n",
    "\n",
    "* See function annotation for info about trait-related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import codecs\n",
    "from collections import namedtuple\n",
    "from enum import Enum\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "WordRecord = namedtuple(\"WordRecord\", [\"defaultform\", \"data\", \"traits\"])\n",
    "\n",
    "PhraseWordRecord = namedtuple(\"PhraseWordRecord\", [\"partofspeech\", \"traits\"])\n",
    "\n",
    "class Animate(Enum):\n",
    "    Animate = 0\n",
    "    Inanimate = 1\n",
    "    def convert(string: str) -> Animate:\n",
    "        switcher = {\n",
    "            'anim': Animate.Animate,\n",
    "            'nanim': Animate.Inanimate\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Gender(Enum):\n",
    "    Male = 0\n",
    "    Female = 1\n",
    "    Neuter = 2\n",
    "    def convert(string: str) -> Gender:\n",
    "        switcher = {\n",
    "            'M': Gender.Male,\n",
    "            'F': Gender.Female,\n",
    "            'N': Gender.Neuter\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Tense(Enum):\n",
    "    Present = 0\n",
    "    Past = 1\n",
    "    Future = 2\n",
    "    def convert(string: str) -> Gender:\n",
    "        switcher = {\n",
    "            'present': Tense.Present,\n",
    "            'past': Tense.Past,\n",
    "            'future': Tense.Future\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Perfectivity(Enum):\n",
    "    Perfect = 0\n",
    "    Imperfect = 1\n",
    "    def convert(string: str) -> Perfectivity:\n",
    "        switcher = {\n",
    "            'perf': Perfectivity.Perfect,\n",
    "            'imperf': Perfectivity.Imperfect\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class PartOfSpeech(Enum):\n",
    "    Noun = 0\n",
    "    Pronoun = 1\n",
    "    Adjective = 2\n",
    "    Verb = 3\n",
    "    def convert(string: str) -> PartOfSpeech:\n",
    "        switcher = {\n",
    "            'N': PartOfSpeech.Noun,\n",
    "            'Pr': PartOfSpeech.Pronoun,\n",
    "            'Adj': PartOfSpeech.Adjective,\n",
    "            'V': PartOfSpeech.Verb\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Quantity(Enum):\n",
    "    Singular = 0\n",
    "    Plural = 1\n",
    "    def convert(string: str) -> Quantity:\n",
    "        switcher = {\n",
    "            'sing': Quantity.Singular,\n",
    "            'pl': Quantity.Plural\n",
    "        }\n",
    "        return switcher[string]\n",
    "\n",
    "class Case(Enum):\n",
    "    Nominative = 0\n",
    "    Genitive = 1\n",
    "    Dative = 2\n",
    "    Accusative = 3\n",
    "    Instrumental = 4\n",
    "    Prepositional = 5\n",
    "    def convert(string: str) -> Case:\n",
    "        switcher = {\n",
    "            'nom': Case.Nominative,\n",
    "            'gen': Case.Genitive,\n",
    "            'dat': Case.Dative,\n",
    "            'acc': Case.Accusative,\n",
    "            'inst': Case.Instrumental,\n",
    "            'prep': Case.Prepositional\n",
    "        }\n",
    "        return switcher[string]\n",
    "\n",
    "class PhraseHead(Enum):\n",
    "    Head = 0\n",
    "    Slave = 1\n",
    "    def convert(string: str) -> Case:\n",
    "        switcher = {\n",
    "            'head': PhraseHead.Head,\n",
    "            'slave': PhraseHead.Slave\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Person(Enum):\n",
    "    P1 = 0\n",
    "    P2 = 1\n",
    "    P3 = 2\n",
    "    def convert(string: str) -> Person:\n",
    "        switcher = {\n",
    "            '1P': Person.P1,\n",
    "            '2P': Person.P2,\n",
    "            '3P': Person.P3\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Transitivity(Enum):\n",
    "    Transitive = 0\n",
    "    Intransitive = 1\n",
    "    def convert(string: str) -> Transitivity:\n",
    "        switcher = {\n",
    "            'tr': Transitivity.Transitive,\n",
    "            'intr': Transitivity.Intransitive\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "cases = [Case.Nominative, Case.Genitive, Case.Dative, Case.Accusative, Case.Instrumental,\n",
    "         Case.Prepositional]\n",
    "persons = [Person.P1, Person.P2, Person.P3]\n",
    "genders = [Gender.Male, Gender.Female, Gender.Neuter]\n",
    "wordTraits = [Animate, Gender, Tense, Perfectivity, Quantity, Case, PhraseHead, Person, Transitivity]\n",
    "partsOfSpeech = [PartOfSpeech.Noun, PartOfSpeech.Pronoun, PartOfSpeech.Adjective, PartOfSpeech.Verb]\n",
    "quantities = [Quantity.Singular, Quantity.Plural]\n",
    "perfTenses = [Tense.Past, Tense.Future]\n",
    "imperfTenses = [Tense.Past, Tense.Present]\n",
    "tenses = [Tense.Past, Tense.Present, Tense.Future]\n",
    "animacy = [Animate.Animate, Animate.Inanimate]\n",
    "perfectivities = [Perfectivity.Perfect, Perfectivity.Imperfect]\n",
    "transitivities = [Transitivity.Transitive, Transitivity.Intransitive]\n",
    "\n",
    "startingNT = \"S\"\n",
    "\n",
    "# imports contents of dictionary and splits it into lines\n",
    "def loadFromFile(path):\n",
    "    with codecs.open(path, 'r', 'utf-8') as dct:\n",
    "        recs = dct.read().splitlines()\n",
    "        return recs\n",
    "\n",
    "# parsing a single trait; utility\n",
    "def parseTrait(tr):\n",
    "    for traitType in wordTraits:\n",
    "        try:\n",
    "            return (traitType, traitType.convert(tr))\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "# parsing a list of traits\n",
    "def parseTraits(trs):\n",
    "    res = dict(zip(wordTraits, [None] * len(wordTraits)))\n",
    "    if len(trs) > 2:\n",
    "        for trait in trs[1:-1].split(';'):\n",
    "            trType, val = parseTrait(trait)\n",
    "            res[trType] = val\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dictionary\n",
    "\n",
    "Dictionary is a text file that contains a specially formatted record with the word's forms and traits. See _dictionary.txt_ for examples. There's no restriction on word number in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "All word records in the dictionary are formatted for easy parsing and loading them into the program. Records for various parts of speech differ considerably, so there is a separate parser for each of them.\n",
    "\n",
    "Currently there are parsers for nouns, pronouns, adjectives and verbs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple case parser\n",
    "def parseCases(caseString):\n",
    "    splitStr = caseString[1:-1].split('|')\n",
    "    if len(splitStr) == 1:\n",
    "        return []\n",
    "    if len(splitStr) < 6:\n",
    "        raise ValueError(\"Invalid case data\", splitStr)\n",
    "    return dict(zip(cases, splitStr))\n",
    "\n",
    "# noun parser\n",
    "def parseNounRec(splitRec):\n",
    "    try:\n",
    "        return WordRecord(splitRec[0], {Quantity.Singular: parseCases(splitRec[1]),\n",
    "                              Quantity.Plural: parseCases(splitRec[2])}, parseTraits(splitRec[3]))\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Failed to import entry:\", splitRec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case parser for male/plural forms of adjectives (with respect to animacy)\n",
    "def parseAnimCases(caseString):\n",
    "    temp = caseString[1:-1].split('|')\n",
    "    temp[3] = temp[3].split(';')\n",
    "    resDict = dict(zip(cases, temp))\n",
    "    resDict[Case.Accusative] = {Animate.Animate: temp[3][0], Animate.Inanimate: temp[3][1]}\n",
    "    return resDict\n",
    "\n",
    "# case parser for adjectives (with respect to genders)\n",
    "def parseAdjSingCases(caseString):\n",
    "    gens = caseString[1:-1].split(' ')\n",
    "    resCases = defaultdict(Gender)\n",
    "    for caseStringGen in gens:\n",
    "        tmp = caseStringGen.split(':')\n",
    "        gend = Gender.convert(tmp[0])\n",
    "        if gend == Gender.Male:\n",
    "            resCases[gend] = parseAnimCases(tmp[1])\n",
    "        else:\n",
    "            resCases[gend] = parseCases(tmp[1])\n",
    "    return resCases\n",
    "\n",
    "# adjective parser\n",
    "def parseAdjRec(splitRec):\n",
    "    return WordRecord(splitRec[0], {Quantity.Singular: parseAdjSingCases(splitRec[1]),\n",
    "                       Quantity.Plural: parseAnimCases(splitRec[2])}, parseTraits(splitRec[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility\n",
    "def parsePastPersonalForms(formString):\n",
    "    temp = formString[1:-1].split('|')\n",
    "    if len(temp) == 3:\n",
    "        return dict(zip(genders, temp))\n",
    "    else:\n",
    "        return temp[0]\n",
    "\n",
    "# for 3-rd person single past forms with respect to gender\n",
    "def parsePersonalForms(formString):\n",
    "    temp = formString[1:-1].split('|')\n",
    "    return dict(zip(persons, temp))\n",
    "\n",
    "# quantity & tense parser\n",
    "def parseVerbForms(formString):\n",
    "    tenses = formString[1:-1].split(' ')\n",
    "    resForms = defaultdict(Tense)\n",
    "    for formString in tenses:\n",
    "        tmp = formString.split(':')\n",
    "        tense = Tense.convert(tmp[0])\n",
    "        if tense == Tense.Past:\n",
    "            resForms[tense] = parsePastPersonalForms(tmp[1])\n",
    "        else:\n",
    "            resForms[tense] = parsePersonalForms(tmp[1])\n",
    "    return resForms\n",
    "\n",
    "# perfectivity parser\n",
    "def perfectivityParser(data):\n",
    "    temp = data[1:-1].split('|')\n",
    "    return Perfectivity.convert(temp[0])\n",
    "        \n",
    "# verb parser\n",
    "def parseVerbRec(splitRec):\n",
    "    res = WordRecord(splitRec[0], {Quantity.Singular: parseVerbForms(splitRec[1]),\n",
    "                                     Quantity.Plural: parseVerbForms(splitRec[2])}, parseTraits(splitRec[3]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser for 3-rd person single form with respect to gender\n",
    "def parse3rdPerson(caseString):\n",
    "    res = defaultdict(Gender)\n",
    "    gens = caseString[1:-1].split(' ')\n",
    "    if len(gens) == 1:\n",
    "        return []\n",
    "    for gen in gens:\n",
    "        genCases = gen.split(':')\n",
    "        res[Gender.convert(genCases[0])] = parseCases(genCases[1])\n",
    "    return res\n",
    "\n",
    "# pronoun parser\n",
    "def parsePronounRec(splitRec):\n",
    "    traits = parseTraits(splitRec[3])\n",
    "    if traits[Person] == Person.P3:\n",
    "        return WordRecord(splitRec[0], {Quantity.Singular: parse3rdPerson(splitRec[1]),\n",
    "                           Quantity.Plural: parseCases(splitRec[2])}, traits)\n",
    "    return WordRecord(splitRec[0], {Quantity.Singular: parseCases(splitRec[1]),\n",
    "                       Quantity.Plural: parseCases(splitRec[2])}, traits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master parser function\n",
    "\n",
    "Without exception handler (in case the entry is formatted incorrectly). Will be added in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsers = [parseNounRec, parsePronounRec, parseAdjRec, parseVerbRec]\n",
    "partOfSpeechParsers = dict(zip(partsOfSpeech, parsers))\n",
    "\n",
    "def parseRecord(rec):\n",
    "    splitRec = rec.split('\\t')\n",
    "    #try:\n",
    "    partofspeech = PartOfSpeech.convert(splitRec[0])\n",
    "    return (partofspeech, partOfSpeechParsers[partofspeech](splitRec[1:]))\n",
    "    #except KeyError:\n",
    "    #    print('Entry will be skipped')\n",
    "    #return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading rules\n",
    "\n",
    "Examples of rules can be found in _rules.txt_. Basic requirements are following:\n",
    "* Starting non-terminal symbol may only have non-terminals in its right part\n",
    "* Ordinary non-terminals may only have terminals in their right part\n",
    "\n",
    "Where non-terminals are phrase aliases that are defined by user, and that consist of one or more terminals; terminals are parts of speech with their traits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & parsing phrase structure: words and their traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parses the passed right part of a phrase alias (part of speech + traits)\n",
    "def parseRightParts(rightPart):\n",
    "    res = []\n",
    "    for part in rightPart.split('|'):\n",
    "        splitPart = part.split(' ')\n",
    "        curWords = []\n",
    "        for _part in splitPart:\n",
    "            rec = _part.split('-')\n",
    "            traits = []\n",
    "            if len(rec) > 1:\n",
    "                traits = rec[1]\n",
    "            curWords.append(PhraseWordRecord(PartOfSpeech.convert(rec[0]), parseTraits(traits)))\n",
    "        res.append(curWords)\n",
    "    return res\n",
    "\n",
    "# returns a set of phrase-building rules\n",
    "def getPhraseStruct(rules):\n",
    "    rulesFinal = {}\n",
    "    for rule in rules:\n",
    "        splitRule = rule.split(':=')\n",
    "        rulesFinal[splitRule[0]] = parseRightParts(splitRule[1])\n",
    "    return rulesFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & parsing non-terminal symbols, denoting overall sentence strucure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parses the passed sentence structure\n",
    "def parseSentHeads(rightPart):\n",
    "    res = []\n",
    "    for part in rightPart:\n",
    "        res.append(part)\n",
    "    return res\n",
    "\n",
    "# returns a set of possible sentence structures for a starting non-terminal\n",
    "def getSentStruct(rules):\n",
    "    rulesFinal = {startingNT: []}\n",
    "    for rule in rules:\n",
    "        sentHead = rule[1:].split(':=')\n",
    "        for part in sentHead[1].split('|'):\n",
    "            if sentHead[0] in rulesFinal:\n",
    "                rulesFinal[sentHead[0]].append(parseSentHeads(part.split()))\n",
    "            elif sentHead[0] in rulesFinal[startingNT]:\n",
    "                rulesFinal[startingNT][sentHead[0]].append(parseSentHeads(part.split()))\n",
    "            else:\n",
    "                rulesFinal[startingNT][sentHead[0]] = parseSentHeads(part.split())\n",
    "    return rulesFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master parser function\n",
    "\n",
    "Runs the utility functions from above and returns fully parsed sets of possible sentence structures and disambiguations of phrase aliases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseRules(rulesSet):\n",
    "    sentRules = []\n",
    "    phraseRules = []\n",
    "    for rule in rulesSet:\n",
    "        if len(rule) == 0:\n",
    "            continue\n",
    "        if rule[0] == '!':\n",
    "            sentRules.append(rule)\n",
    "        elif rule[0] != '#':\n",
    "            phraseRules.append(rule)           \n",
    "    return (getSentStruct(sentRules), getPhraseStruct(phraseRules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binding the components together: sentence generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General functions and useful dictionaries\n",
    "\n",
    "Introducing lists with traits of each part of speech _(1)_, lists with traits that phrase heads pass as lingering agreement _(2)_, lists of traits that are passed from word to word inside a phrase _(3)_ and functions that update them.\n",
    "\n",
    "Lingering agreement is passed from one phrase to another: for example, a pronoun will pass its person to the following verb phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1)\n",
    "nounTraits = [Animate, Gender, Quantity, Case, PhraseHead]\n",
    "pronounTraits = [Animate, Gender, Quantity, Case, PhraseHead, Person]\n",
    "adjectiveTraits = [Animate, Gender, Quantity, Case, PhraseHead]\n",
    "verbTraits = [Gender, Tense, Perfectivity, Quantity, PhraseHead, Person, Transitivity]\n",
    "posTraits = dict(zip(partsOfSpeech, [nounTraits, pronounTraits, adjectiveTraits, verbTraits]))\n",
    "\n",
    "# (2)\n",
    "passingHeadNounTraits = [Animate, Gender, Quantity, Person]\n",
    "passingHeadPronounTraits = [Gender, Quantity, Person]\n",
    "passingHeadAdjectiveTraits = []\n",
    "passingHeadVerbTraits = [Transitivity]\n",
    "passingHeadPosTraits = dict(zip(partsOfSpeech, [passingHeadNounTraits, passingHeadPronounTraits,\n",
    "                                                passingHeadAdjectiveTraits, passingHeadVerbTraits]))\n",
    "\n",
    "# (3)\n",
    "passingNounTraits = [Animate, Gender, Quantity, Case]\n",
    "passingPronounTraits = [Gender, Quantity, Person, Case]\n",
    "passingAdjectiveTraits = [] # ???\n",
    "passingVerbTraits = [] # ???\n",
    "passingPosTraits = dict(zip(partsOfSpeech, [passingNounTraits, passingPronounTraits,\n",
    "                                                passingAdjectiveTraits, passingVerbTraits]))\n",
    "\n",
    "def updateWordTraits(word, agr, pos):\n",
    "    for tr in posTraits[pos]:\n",
    "        if word.traits[tr] == None:\n",
    "            word.traits[tr] = agr[tr]\n",
    "\n",
    "def updateLingeringAgreement(word, agr, pos):\n",
    "    for tr in agr:\n",
    "        if not tr in passingPosTraits[pos]:\n",
    "            agr[tr] = None\n",
    "        else:\n",
    "            agr[tr] = word.traits[tr]\n",
    "            \n",
    "def updateHeadLingeringAgreement(word, agr, pos):\n",
    "    for tr in agr:\n",
    "        if not tr in passingHeadPosTraits[pos]:\n",
    "            agr[tr] = None\n",
    "        else:\n",
    "            agr[tr] = word.traits[tr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement production\n",
    "\n",
    "Rules contain crucial parts of agreement; other parts of it are generated according to the lingering agreement or chosen randomly. Resulting traits are later used for choosing words and its forms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjAgreement(word, lingeringAgreement):\n",
    "    updateWordTraits(word, lingeringAgreement, word.partofspeech)\n",
    "    if word.traits[Quantity] == None:\n",
    "        word.traits[Quantity] = random.choice(quantities)\n",
    "    if word.traits[Animate] == None:\n",
    "        word.traits[Animate] = random.choice(animacy)\n",
    "    if word.traits[Gender] == None:\n",
    "        if word.traits[Animate] == Animate.Animate:\n",
    "            word.traits[Gender] = random.choice(genders[:-1])\n",
    "    word.traits[Person] = Person.P3\n",
    "    if word.traits[Case] == None:\n",
    "        if lingeringAgreement[Transitivity] == Transitivity.Transitive:\n",
    "            word.traits[Case] = Case.Accusative\n",
    "        elif lingeringAgreement[Transitivity] == None:\n",
    "            word.traits[Case] = Case.Nominative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbAgreement(word, lingeringAgreement):\n",
    "    updateWordTraits(word, lingeringAgreement, word.partofspeech)\n",
    "    if word.traits[Transitivity] == None:\n",
    "        word.traits[Transitivity] = random.choice(transitivities)\n",
    "    if word.traits[Perfectivity] == None:\n",
    "        word.traits[Perfectivity] = random.choice(perfectivities)\n",
    "    if word.traits[Tense] == None:\n",
    "        if word.traits[Perfectivity] == Perfectivity.Perfect:\n",
    "            word.traits[Tense] = random.choice(perfTenses)\n",
    "        else:\n",
    "            word.traits[Tense] = random.choice(imperfTenses)\n",
    "    if word.traits[Tense] == Tense.Past:\n",
    "        if word.traits[Gender] == None:\n",
    "            word.traits[Gender] = random.choice(genders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nounAgreement(word, lingeringAgreement):\n",
    "    updateWordTraits(word, lingeringAgreement, word.partofspeech)\n",
    "    if word.traits[Quantity] == None:\n",
    "        word.traits[Quantity] = random.choice(quantities)\n",
    "    if word.traits[Animate] == None:\n",
    "        word.traits[Animate] = random.choice(animacy)\n",
    "    if word.traits[Gender] == None:\n",
    "        if word.traits[Animate] == Animate.Animate:\n",
    "            word.traits[Gender] = random.choice(genders[:-1])\n",
    "        else:\n",
    "            word.traits[Gender] = random.choice(genders)\n",
    "    word.traits[Person] = Person.P3\n",
    "    if word.traits[Case] == None:\n",
    "        if lingeringAgreement[Transitivity] == Transitivity.Transitive:\n",
    "            word.traits[Case] = Case.Accusative\n",
    "        elif lingeringAgreement[Transitivity] == None:\n",
    "            word.traits[Case] = Case.Nominative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronounAgreement(word, lingeringAgreement):\n",
    "    updateWordTraits(word, lingeringAgreement, word.partofspeech)\n",
    "    if word.traits[Quantity] == None:\n",
    "        word.traits[Quantity] = random.choice(quantities)\n",
    "    if word.traits[Case] == None:\n",
    "        if lingeringAgreement[Transitivity] == Transitivity.Transitive:\n",
    "            word.traits[Case] = Case.Accusative\n",
    "        elif lingeringAgreement[Transitivity] == None:\n",
    "            word.traits[Case] = Case.Nominative\n",
    "    if word.traits[Animate] == None:\n",
    "        word.traits[Animate] = random.choice(animacy)\n",
    "    if word.traits[Person] == None:\n",
    "        word.traits[Person] = random.choice(persons)\n",
    "    if word.traits[Quantity] == Quantity.Singular:\n",
    "        if word.traits[Gender] == None:\n",
    "            if word.traits[Animate] == Animate.Animate:\n",
    "                word.traits[Gender] = random.choice(genders[:-1])\n",
    "            else:\n",
    "                word.traits[Gender] = random.choice(genders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few more dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement = [nounAgreement, pronounAgreement, adjAgreement, verbAgreement]\n",
    "agreementSetter = dict(zip(partsOfSpeech, agreement))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word picker functions\n",
    "\n",
    "Used for picking a right form of the required speech part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickPronoun(dct, traits):\n",
    "    for entry in dct[PartOfSpeech.Pronoun]:\n",
    "        if entry.traits[Person] == traits[Person]:\n",
    "            if traits[Person] != Person.P3:\n",
    "                return entry.data[traits[Quantity]][traits[Case]]\n",
    "            else:\n",
    "                if traits[Quantity] != Quantity.Singular:\n",
    "                    return entry.data[traits[Quantity]][traits[Case]]\n",
    "                else:\n",
    "                    return entry.data[traits[Quantity]][traits[Gender]][traits[Case]]\n",
    "                \n",
    "def pickVerb(dct, traits):\n",
    "    pool = []\n",
    "    for entry in dct[PartOfSpeech.Verb]:\n",
    "        if entry.traits[Transitivity] == traits[Transitivity]:\n",
    "            if entry.traits[Perfectivity] == traits[Perfectivity]:\n",
    "                pool.append(entry)\n",
    "    finalChoice = random.choice(pool)\n",
    "    if traits[Quantity] == Quantity.Plural:\n",
    "        if traits[Tense] == Tense.Past:\n",
    "            return finalChoice.data[traits[Quantity]][traits[Tense]]\n",
    "        else:\n",
    "             return finalChoice.data[traits[Quantity]][traits[Tense]][traits[Person]]\n",
    "    else:\n",
    "        if traits[Tense] == Tense.Past:\n",
    "            return finalChoice.data[traits[Quantity]][traits[Tense]][traits[Gender]]\n",
    "        else:\n",
    "            return finalChoice.data[traits[Quantity]][traits[Tense]][traits[Person]]\n",
    "\n",
    "def pickNoun(dct, traits):\n",
    "    pool = []\n",
    "    for entry in dct[PartOfSpeech.Noun]:\n",
    "        if entry.traits[Animate] == traits[Animate]:\n",
    "            if entry.traits[Gender] == traits[Gender]:\n",
    "                pool.append(entry)\n",
    "    finalChoice = random.choice(pool)\n",
    "    return finalChoice.data[traits[Quantity]][traits[Case]]\n",
    "    \n",
    "def pickAdjective(dct, traits):\n",
    "    pool = []\n",
    "    for entry in dct[PartOfSpeech.Adjective]:\n",
    "        pool.append(entry)\n",
    "    finalChoice = random.choice(pool)\n",
    "    if traits[Quantity] == Quantity.Plural:\n",
    "        if traits[Case] != Case.Accusative:\n",
    "            return finalChoice.data[traits[Quantity]][traits[Case]]\n",
    "        else:\n",
    "            return finalChoice.data[traits[Quantity]][traits[Case]][traits[Animate]]\n",
    "    else:\n",
    "        if (traits[Case] == Case.Accusative) and (traits[Gender] == Gender.Male):\n",
    "            return finalChoice.data[traits[Quantity]][traits[Gender]][traits[Case]][traits[Animate]]\n",
    "        else:\n",
    "            return finalChoice.data[traits[Quantity]][traits[Gender]][traits[Case]]\n",
    "\n",
    "wordPickers = [pickNoun, pickPronoun, pickAdjective, pickVerb]\n",
    "findWord = dict(zip(partsOfSpeech, wordPickers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence generator\n",
    "\n",
    "__getHeadInd__ returns the index of a phrase head.\n",
    "\n",
    "__sentGenerator__ takes the dictionary, sentence patterns and phrase-building rules and returns a syntactically grammatical sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHeadInd(phraseRule):\n",
    "    for i in range(0, len(phraseRule)):\n",
    "        if phraseRule[i].traits[PhraseHead] == PhraseHead.Head:\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "\n",
    "def sentGenerator(dct, sentPattern, rules, Yoda):\n",
    "    lingeringAgreementEmpty = True\n",
    "    lingeringAgreement = dict()\n",
    "    finalSentence = []\n",
    "    for pat in sentPattern:\n",
    "        curPhrase = random.choice(rules[pat]) # choosing a right-part (phrase) from available for the current non-terminal\n",
    "        headInd = getHeadInd(curPhrase) # getting the head of the phrase\n",
    "        if lingeringAgreementEmpty:\n",
    "            for tr in wordTraits:\n",
    "                lingeringAgreement.update({tr: curPhrase[headInd].traits[tr]})\n",
    "            lingeringAgreementEmpty = False\n",
    "        grammaticalPhrase = [None] * len(curPhrase)\n",
    "        grammaticalPhrase[headInd] = agreementSetter[curPhrase[headInd].partofspeech](curPhrase[headInd], lingeringAgreement)\n",
    "        updateLingeringAgreement(curPhrase[headInd], lingeringAgreement, curPhrase[headInd].partofspeech)\n",
    "        \n",
    "        for i in range(0, len(curPhrase)):\n",
    "            if i != headInd:\n",
    "                grammaticalPhrase[i] = agreementSetter[curPhrase[i].partofspeech](curPhrase[i], lingeringAgreement)\n",
    "            finalSentence.append(findWord[curPhrase[i].partofspeech](dct, curPhrase[i].traits))\n",
    "        updateHeadLingeringAgreement(curPhrase[headInd], lingeringAgreement, curPhrase[headInd].partofspeech)\n",
    "    if Yoda:\n",
    "        finalSentence.reverse()\n",
    "    return \" \".join(finalSentence).capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master \"main\" function\n",
    "\n",
    "Takes paths to files with dictionary and rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(Yoda = False, dctPath = './dictionary.txt', rulesPath = './rules.txt'):\n",
    "    contents = loadFromFile(dctPath)\n",
    "    dct = defaultdict(PartOfSpeech)\n",
    "    for part in partsOfSpeech:\n",
    "        dct[part] = []\n",
    "    for entry in contents:\n",
    "        partOfSpeech, rec = parseRecord(entry)\n",
    "        dct[partOfSpeech].append(rec)\n",
    "        \n",
    "\n",
    "    contents = loadFromFile(rulesPath)\n",
    "    sentStruct, rules = parseRules(contents)\n",
    "\n",
    "    return sentGenerator(dct, random.choice(sentStruct[startingNT]), rules, Yoda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test area\n",
    "\n",
    "Run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мы видели их\n"
     ]
    }
   ],
   "source": [
    "# Yoda-style!\n",
    "#print(main(True))\n",
    "\n",
    "# regular sentence\n",
    "print(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
