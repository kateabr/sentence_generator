{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import codecs\n",
    "from collections import namedtuple\n",
    "from enum import Enum\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import random\n",
    "\n",
    "WordRecord = namedtuple(\"WordRecord\", [\"defaultform\", \"quantityData\", \"traits\"])\n",
    "\n",
    "PhraseWordRecord = namedtuple(\"PhraseWordRecord\", [\"partofspeech\", \"traits\"])\n",
    "\n",
    "class Animate(Enum):\n",
    "    Animate = 0\n",
    "    Inanimate = 1\n",
    "    def convert(string: str) -> Animate:\n",
    "        switcher = {\n",
    "            'anim': Animate.Animate,\n",
    "            'nanim': Animate.Inanimate\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Gender(Enum):\n",
    "    Male = 0\n",
    "    Female = 1\n",
    "    Neuter = 2\n",
    "    def convert(string: str) -> Gender:\n",
    "        switcher = {\n",
    "            'M': Gender.Male,\n",
    "            'F': Gender.Female,\n",
    "            'N': Gender.Neuter\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Tense(Enum):\n",
    "    Present = 0\n",
    "    Past = 1\n",
    "    Future = 2\n",
    "    def convert(string: str) -> Gender:\n",
    "        switcher = {\n",
    "            'present': Tense.Present,\n",
    "            'past': Tense.Past,\n",
    "            'future': Tense.Future\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Perfectivity(Enum):\n",
    "    Perfect = 0\n",
    "    Imperfect = 1\n",
    "    def convert(string: str) -> Perfectivity:\n",
    "        switcher = {\n",
    "            'perf': Perfectivity.Perfect,\n",
    "            'imperf': Perfectivity.Imperfect\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class PartOfSpeech(Enum):\n",
    "    Noun = 0\n",
    "    Pronoun = 1\n",
    "    Adjective = 2\n",
    "    Verb = 3\n",
    "    def convert(string: str) -> PartOfSpeech:\n",
    "        switcher = {\n",
    "            'N': PartOfSpeech.Noun,\n",
    "            'Pr': PartOfSpeech.Pronoun,\n",
    "            'Adj': PartOfSpeech.Adjective,\n",
    "            'V': PartOfSpeech.Verb\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Phrase(Enum):\n",
    "    SNP = 0\n",
    "    VP = 1\n",
    "    ONP = 2\n",
    "    NP = 3\n",
    "    S = 4\n",
    "    def convert(string: str) -> Phrase:\n",
    "        switcher = {\n",
    "            'SNP': Phrase.SNP,\n",
    "            'VP': Phrase.VP,\n",
    "            'ONP': Phrase.ONP,\n",
    "            'NP': Phrase.NP,\n",
    "            'S': Phrase.S\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Quantity(Enum):\n",
    "    Singular = 0\n",
    "    Plural = 1\n",
    "    def convert(string: str) -> Quantity:\n",
    "        switcher = {\n",
    "            'sing': Quantity.Singular,\n",
    "            'pl': Quantity.Plural\n",
    "        }\n",
    "        return switcher[string]\n",
    "\n",
    "class Case(Enum):\n",
    "    Nominative = 0\n",
    "    Genitive = 1\n",
    "    Dative = 2\n",
    "    Accusative = 3\n",
    "    Instrumental = 4\n",
    "    Prepositional = 5\n",
    "    def convert(string: str) -> Case:\n",
    "        switcher = {\n",
    "            'nom': Case.Nominative,\n",
    "            'gen': Case.Genitive,\n",
    "            'dat': Case.Dative,\n",
    "            'acc': Case.Accusative,\n",
    "            'inst': Case.Instrumental,\n",
    "            'prep': Case.Prepositional\n",
    "        }\n",
    "        return switcher[string]\n",
    "\n",
    "class PhraseHead(Enum):\n",
    "    IsHead = 0\n",
    "    def convert(string: str) -> Case:\n",
    "        switcher = {\n",
    "            'head': PhraseHead.IsHead\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Person(Enum):\n",
    "    P1 = 0\n",
    "    P2 = 1\n",
    "    P3 = 2\n",
    "    def convert(string: str) -> Person:\n",
    "        switcher = {\n",
    "            '1P': Person.P1,\n",
    "            '2P': Person.P2,\n",
    "            '3P': Person.P3\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Transitivity(Enum):\n",
    "    Transitive = 0\n",
    "    Intransitive = 1\n",
    "    def convert(string: str) -> Transitivity:\n",
    "        switcher = {\n",
    "            'tr': Transitivity.Transitive,\n",
    "            'intr': Transitivity.Intransitive\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "cases = [Case.Nominative, Case.Genitive, Case.Dative, Case.Accusative, Case.Instrumental,\n",
    "         Case.Prepositional]\n",
    "persons = [Person.P1, Person.P2, Person.P3]\n",
    "genders = [Gender.Male, Gender.Female, Gender.Neuter]\n",
    "wordTraits = [Animate, Gender, Tense, Perfectivity, Quantity, Case, PhraseHead, Person, Transitivity]\n",
    "partsOfSpeech = [PartOfSpeech.Noun, PartOfSpeech.Pronoun, PartOfSpeech.Adjective, PartOfSpeech.Verb]\n",
    "\n",
    "# imports contents of dictionary and splits it into lines\n",
    "def loadFromFile(path):\n",
    "    with codecs.open(path, 'r', 'utf-8') as dct:\n",
    "        recs = dct.read().splitlines()\n",
    "        return recs\n",
    "    \n",
    "def parseTrait(tr):\n",
    "    for traitType in wordTraits:\n",
    "        try:\n",
    "            return traitType.convert(tr)\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "def parseTraits(trs):\n",
    "    res = []\n",
    "    if len(trs) > 0:\n",
    "        for trait in trs[1:-1].split(';'):\n",
    "            res.append(parseTrait(trait))\n",
    "    return set(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple case parser\n",
    "def parseCases(caseString):\n",
    "    splitStr = caseString[1:-1].split('|')\n",
    "    if len(splitStr) == 1:\n",
    "        return []\n",
    "    if len(splitStr) < 6:\n",
    "        raise ValueError(\"Invalid case data\", splitStr)\n",
    "    return dict(zip(cases, splitStr))\n",
    "\n",
    "# noun parser\n",
    "def parseNounRec(splitRec):\n",
    "    try:\n",
    "        return WordRecord(splitRec[0], {Quantity.Singular: parseCases(splitRec[1]),\n",
    "                              Quantity.Plural: parseCases(splitRec[2])}, parseTraits(splitRec[3]))\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Failed to import entry:\", splitRec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case parser for male forms of adjectives (with respect to animacy)\n",
    "def parseMaleCases(caseString):\n",
    "    temp = caseString[1:-1].split('|')\n",
    "    temp[3] = temp[3].split(';')\n",
    "    resDict = dict(zip(cases, temp))\n",
    "    resDict['acc'] = {(Animate.Animate, temp[3][0]), (Animate.Inanimate, temp[3][1])}\n",
    "    return resDict\n",
    "\n",
    "# case parser for adjectives (with respect to genders)\n",
    "def parseAdjSingCases(caseString):\n",
    "    gens = caseString[1:-1].split(' ')\n",
    "    resCases = defaultdict(Gender)\n",
    "    for caseStringGen in gens:\n",
    "        tmp = caseStringGen.split(':')\n",
    "        gend = Gender.convert(tmp[0])\n",
    "        if gend == Gender.Male:\n",
    "            resCases[gend] = parseMaleCases(tmp[1])\n",
    "        else:\n",
    "            resCases[gend] = parseCases(tmp[1])\n",
    "    return resCases\n",
    "\n",
    "# adjective parser\n",
    "def parseAdjRec(splitRec):\n",
    "    return WordRecord(splitRec[0], {Quantity.Singular: parseAdjSingCases(splitRec[1]),\n",
    "                       Quantity.Plural: parseCases(splitRec[2])}, parseTraits(splitRec[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePastPersonalForms(formString):\n",
    "    temp = formString[1:-1].split('|')\n",
    "    if len(temp) == 3:\n",
    "        return dict(zip(genders, temp))\n",
    "    else:\n",
    "        return temp[0]\n",
    "\n",
    "def parsePersonalForms(formString):\n",
    "    temp = formString[1:-1].split('|')\n",
    "    return dict(zip(persons, temp))\n",
    "\n",
    "def parseVerbForms(formString):\n",
    "    tenses = formString[1:-1].split(' ')\n",
    "    resForms = defaultdict(Tense)\n",
    "    for formString in tenses:\n",
    "        tmp = formString.split(':')\n",
    "        tense = Tense.convert(tmp[0])\n",
    "        if tense == Tense.Past:\n",
    "            resForms[tense] = parsePastPersonalForms(tmp[1])\n",
    "        else:\n",
    "            resForms[tense] = parsePersonalForms(tmp[1])\n",
    "    return resForms\n",
    "\n",
    "def perfectivityParser(data):\n",
    "    temp = data[1:-1].split('|')\n",
    "    return Perfectivity.convert(temp[0])\n",
    "        \n",
    "def parseVerbRec(splitRec):\n",
    "    res = WordRecord(splitRec[0], {Quantity.Singular: parseVerbForms(splitRec[1]),\n",
    "                                     Quantity.Plural: parseVerbForms(splitRec[2])}, parseTraits(splitRec[3]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePronounRec(splitRec):\n",
    "    return WordRecord(splitRec[0], {Quantity.Singular: parseCases(splitRec[1]),\n",
    "                       Quantity.Plural: parseCases(splitRec[2])}, parseTraits(splitRec[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master parser function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsers = [parseNounRec, parsePronounRec, parseAdjRec, parseVerbRec]\n",
    "partOfSpeechParsers = dict(zip(partsOfSpeech, parsers))\n",
    "\n",
    "def parseRecord(rec):\n",
    "    splitRec = rec.split('\\t')\n",
    "    #try:\n",
    "    partofspeech = PartOfSpeech.convert(splitRec[0])\n",
    "    return (partofspeech, partOfSpeechParsers[partofspeech](splitRec[1:]))\n",
    "#    if partofspeech == PartOfSpeech.Noun:\n",
    "#        return (partofspeech, parseNounRec(splitRec))\n",
    "#    elif partofspeech == PartOfSpeech.Adjective:\n",
    "#        return (partofspeech, parseAdjRec(splitRec))\n",
    "#    elif partofspeech == PartOfSpeech.Verb:\n",
    "#        return (partofspeech, parseVerbRec(splitRec))\n",
    "#    elif partofspeech == PartOfSpeech.Pronoun:\n",
    "#        return (partofspeech, parsePronounRec(splitRec))\n",
    "    #except KeyError:\n",
    "    #    print('Entry will be skipped')\n",
    "    #return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & parsing phrase structure: words and their traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseRightParts(rightPart):\n",
    "    res = []\n",
    "    for part in rightPart.split('|'):\n",
    "        splitPart = part.split(' ')\n",
    "        curWords = []\n",
    "        for _part in splitPart:\n",
    "            rec = _part.split('-')\n",
    "            traits = []\n",
    "            if len(rec) > 1:\n",
    "                traits = rec[1]\n",
    "            curWords.append(PhraseWordRecord(PartOfSpeech.convert(rec[0]), parseTraits(traits)))\n",
    "        res.append(curWords)\n",
    "    return res\n",
    "\n",
    "def getPhraseStruct(rules):\n",
    "    rulesFinal = {}\n",
    "    for rule in rules:\n",
    "        splitRule = rule.split(':=')\n",
    "        rulesFinal[Phrase.convert(splitRule[0])] = parseRightParts(splitRule[1])\n",
    "    return rulesFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & parsing non-terminal symbols, denoting overall sentence strucure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSentHeads(rightPart):\n",
    "    res = []\n",
    "    for part in rightPart:\n",
    "        res.append(Phrase.convert(part))\n",
    "    return res\n",
    "\n",
    "def getSentStruct(rules):\n",
    "    rulesFinal = {Phrase.S: []}\n",
    "    for rule in rules:\n",
    "        sentHead = rule[1:].split(':=')\n",
    "        for part in sentHead[1].split('|'):\n",
    "            if Phrase.convert(sentHead[0]) in rulesFinal:\n",
    "                rulesFinal[Phrase.convert(sentHead[0])].append(parseSentHeads(part.split()))\n",
    "            elif Phrase.convert(sentHead[0]) in rulesFinal[Phrase.S]:\n",
    "                rulesFinal[Phrase.S][Phrase.convert(sentHead[0])].append(parseSentHeads(part.split()))\n",
    "            else:\n",
    "                rulesFinal[Phrase.S][Phrase.convert(sentHead[0])] = parseSentHeads(part.split())\n",
    "    return rulesFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master parser function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseRules(rulesSet):\n",
    "    sentRules = []\n",
    "    phraseRules = []\n",
    "    for rule in rulesSet:\n",
    "        if len(rule) == 0:\n",
    "            continue\n",
    "        if rule[0] == '!':\n",
    "            sentRules.append(rule)\n",
    "        elif rule[0] != '#':\n",
    "            phraseRules.append(rule)           \n",
    "    return (getSentStruct(sentRules), getPhraseStruct(phraseRules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binding the components together: sentence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentGenerator(dct, sentStruct, rules):\n",
    "    pattern = random.choice(sentStruct[Phrase.S])\n",
    "    base = []\n",
    "    for elem in pattern:\n",
    "        base.append(random.choice(rules[elem]))\n",
    "    sent = []\n",
    "    print(base)\n",
    "    phraseWithWords = []\n",
    "    for phrase in base:\n",
    "        for _word in phrase:\n",
    "            sent.append(random.choice(dct[_word.partofspeech]).defaultform)\n",
    "    print(sent)\n",
    "    #print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master \"main\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dctPath = './dictionary.txt', rulesPath = './rules.txt'):\n",
    "    contents = loadFromFile(dctPath)\n",
    "    dct = defaultdict(PartOfSpeech)\n",
    "    for part in partsOfSpeech:\n",
    "        dct[part] = []\n",
    "    for entry in contents:\n",
    "        partOfSpeech, rec = parseRecord(entry)\n",
    "        dct[partOfSpeech].append(rec)\n",
    "    contents = loadFromFile(rulesPath)\n",
    "    sentStruct, rules = parseRules(contents)\n",
    "    sentGenerator(dct, sentStruct, rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[PhraseWordRecord(partofspeech=<PartOfSpeech.Pronoun: 1>, traits={<Case.Nominative: 0>})], [PhraseWordRecord(partofspeech=<PartOfSpeech.Verb: 3>, traits={<Transitivity.Transitive: 0>})], [PhraseWordRecord(partofspeech=<PartOfSpeech.Adjective: 2>, traits={None}), PhraseWordRecord(partofspeech=<PartOfSpeech.Noun: 0>, traits={<PhraseHead.IsHead: 0>, <Case.Accusative: 3>})]]\n",
      "['волк', 'серый', 'видеть', 'я']\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordRecord(defaultform='я', partofspeech=<PartOfSpeech.Pronoun: 1>, quantityData={<Quantity.Singular: 0>: {<Case.Nominative: 0>: 'я', <Case.Genitive: 1>: 'меня', <Case.Dative: 2>: 'мне', <Case.Accusative: 3>: 'меня', <Case.Instrumental: 4>: 'мной', <Case.Prepositional: 5>: 'мне'}, <Quantity.Plural: 1>: {<Case.Nominative: 0>: 'мы', <Case.Genitive: 1>: 'нас', <Case.Dative: 2>: 'нам', <Case.Accusative: 3>: 'нас', <Case.Instrumental: 4>: 'нами', <Case.Prepositional: 5>: 'нас'}}, traits={None})\n"
     ]
    }
   ],
   "source": [
    "recs = loadFromFile('./dictionary.txt')\n",
    "print(parseRecord(recs[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
