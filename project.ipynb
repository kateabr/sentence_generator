{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import codecs\n",
    "from collections import namedtuple\n",
    "from enum import Enum\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import random\n",
    "\n",
    "WordRecord = namedtuple(\"WordRecord\", [\"defaultform\", \"data\", \"traits\"])\n",
    "\n",
    "PhraseWordRecord = namedtuple(\"PhraseWordRecord\", [\"partofspeech\", \"traits\"])\n",
    "\n",
    "class Animate(Enum):\n",
    "    Animate = 0\n",
    "    Inanimate = 1\n",
    "    def convert(string: str) -> Animate:\n",
    "        switcher = {\n",
    "            'anim': Animate.Animate,\n",
    "            'nanim': Animate.Inanimate\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Gender(Enum):\n",
    "    Male = 0\n",
    "    Female = 1\n",
    "    Neuter = 2\n",
    "    def convert(string: str) -> Gender:\n",
    "        switcher = {\n",
    "            'M': Gender.Male,\n",
    "            'F': Gender.Female,\n",
    "            'N': Gender.Neuter\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Tense(Enum):\n",
    "    Present = 0\n",
    "    Past = 1\n",
    "    Future = 2\n",
    "    def convert(string: str) -> Gender:\n",
    "        switcher = {\n",
    "            'present': Tense.Present,\n",
    "            'past': Tense.Past,\n",
    "            'future': Tense.Future\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Perfectivity(Enum):\n",
    "    Perfect = 0\n",
    "    Imperfect = 1\n",
    "    def convert(string: str) -> Perfectivity:\n",
    "        switcher = {\n",
    "            'perf': Perfectivity.Perfect,\n",
    "            'imperf': Perfectivity.Imperfect\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class PartOfSpeech(Enum):\n",
    "    Noun = 0\n",
    "    Pronoun = 1\n",
    "    Adjective = 2\n",
    "    Verb = 3\n",
    "    def convert(string: str) -> PartOfSpeech:\n",
    "        switcher = {\n",
    "            'N': PartOfSpeech.Noun,\n",
    "            'Pr': PartOfSpeech.Pronoun,\n",
    "            'Adj': PartOfSpeech.Adjective,\n",
    "            'V': PartOfSpeech.Verb\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Quantity(Enum):\n",
    "    Singular = 0\n",
    "    Plural = 1\n",
    "    def convert(string: str) -> Quantity:\n",
    "        switcher = {\n",
    "            'sing': Quantity.Singular,\n",
    "            'pl': Quantity.Plural\n",
    "        }\n",
    "        return switcher[string]\n",
    "\n",
    "class Case(Enum):\n",
    "    Nominative = 0\n",
    "    Genitive = 1\n",
    "    Dative = 2\n",
    "    Accusative = 3\n",
    "    Instrumental = 4\n",
    "    Prepositional = 5\n",
    "    def convert(string: str) -> Case:\n",
    "        switcher = {\n",
    "            'nom': Case.Nominative,\n",
    "            'gen': Case.Genitive,\n",
    "            'dat': Case.Dative,\n",
    "            'acc': Case.Accusative,\n",
    "            'inst': Case.Instrumental,\n",
    "            'prep': Case.Prepositional\n",
    "        }\n",
    "        return switcher[string]\n",
    "\n",
    "class PhraseHead(Enum):\n",
    "    Head = 0\n",
    "    Slave = 0\n",
    "    def convert(string: str) -> Case:\n",
    "        switcher = {\n",
    "            'head': PhraseHead.Head,\n",
    "            'slave': PhraseHead.Slave\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Person(Enum):\n",
    "    P1 = 0\n",
    "    P2 = 1\n",
    "    P3 = 2\n",
    "    def convert(string: str) -> Person:\n",
    "        switcher = {\n",
    "            '1P': Person.P1,\n",
    "            '2P': Person.P2,\n",
    "            '3P': Person.P3\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Transitivity(Enum):\n",
    "    Transitive = 0\n",
    "    Intransitive = 1\n",
    "    def convert(string: str) -> Transitivity:\n",
    "        switcher = {\n",
    "            'tr': Transitivity.Transitive,\n",
    "            'intr': Transitivity.Intransitive\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "cases = [Case.Nominative, Case.Genitive, Case.Dative, Case.Accusative, Case.Instrumental,\n",
    "         Case.Prepositional]\n",
    "persons = [Person.P1, Person.P2, Person.P3]\n",
    "genders = [Gender.Male, Gender.Female, Gender.Neuter]\n",
    "wordTraits = [Animate, Gender, Tense, Perfectivity, Quantity, Case, PhraseHead, Person, Transitivity]\n",
    "partsOfSpeech = [PartOfSpeech.Noun, PartOfSpeech.Pronoun, PartOfSpeech.Adjective, PartOfSpeech.Verb]\n",
    "quantities = [Quantity.Singular, Quantity.Plural]\n",
    "\n",
    "startingNT = \"S\"\n",
    "\n",
    "# imports contents of dictionary and splits it into lines\n",
    "def loadFromFile(path):\n",
    "    with codecs.open(path, 'r', 'utf-8') as dct:\n",
    "        recs = dct.read().splitlines()\n",
    "        return recs\n",
    "    \n",
    "def parseTrait(tr):\n",
    "    for traitType in wordTraits:\n",
    "        try:\n",
    "            return (traitType, traitType.convert(tr))\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "def parseTraits(trs):\n",
    "    res = dict(zip(wordTraits, [None] * len(wordTraits)))\n",
    "    if len(trs) > 2:\n",
    "        for trait in trs[1:-1].split(';'):\n",
    "            trType, val = parseTrait(trait)\n",
    "            res[trType] = val\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple case parser\n",
    "def parseCases(caseString):\n",
    "    splitStr = caseString[1:-1].split('|')\n",
    "    if len(splitStr) == 1:\n",
    "        return []\n",
    "    if len(splitStr) < 6:\n",
    "        raise ValueError(\"Invalid case data\", splitStr)\n",
    "    return dict(zip(cases, splitStr))\n",
    "\n",
    "# noun parser\n",
    "def parseNounRec(splitRec):\n",
    "    try:\n",
    "        return WordRecord(splitRec[0], {Quantity.Singular: parseCases(splitRec[1]),\n",
    "                              Quantity.Plural: parseCases(splitRec[2])}, parseTraits(splitRec[3]))\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Failed to import entry:\", splitRec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case parser for male/plural forms of adjectives (with respect to animacy)\n",
    "def parseAnimCases(caseString):\n",
    "    temp = caseString[1:-1].split('|')\n",
    "    temp[3] = temp[3].split(';')\n",
    "    resDict = dict(zip(cases, temp))\n",
    "    resDict[Case.Accusative] = {(Animate.Animate, temp[3][0]), (Animate.Inanimate, temp[3][1])}\n",
    "    return resDict\n",
    "\n",
    "# case parser for adjectives (with respect to genders)\n",
    "def parseAdjSingCases(caseString):\n",
    "    gens = caseString[1:-1].split(' ')\n",
    "    resCases = defaultdict(Gender)\n",
    "    for caseStringGen in gens:\n",
    "        tmp = caseStringGen.split(':')\n",
    "        gend = Gender.convert(tmp[0])\n",
    "        if gend == Gender.Male:\n",
    "            resCases[gend] = parseAnimCases(tmp[1])\n",
    "        else:\n",
    "            resCases[gend] = parseCases(tmp[1])\n",
    "    return resCases\n",
    "\n",
    "# adjective parser\n",
    "def parseAdjRec(splitRec):\n",
    "    return WordRecord(splitRec[0], {Quantity.Singular: parseAdjSingCases(splitRec[1]),\n",
    "                       Quantity.Plural: parseAnimCases(splitRec[2])}, parseTraits(splitRec[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePastPersonalForms(formString):\n",
    "    temp = formString[1:-1].split('|')\n",
    "    if len(temp) == 3:\n",
    "        return dict(zip(genders, temp))\n",
    "    else:\n",
    "        return temp[0]\n",
    "\n",
    "def parsePersonalForms(formString):\n",
    "    temp = formString[1:-1].split('|')\n",
    "    return dict(zip(persons, temp))\n",
    "\n",
    "def parseVerbForms(formString):\n",
    "    tenses = formString[1:-1].split(' ')\n",
    "    resForms = defaultdict(Tense)\n",
    "    for formString in tenses:\n",
    "        tmp = formString.split(':')\n",
    "        tense = Tense.convert(tmp[0])\n",
    "        if tense == Tense.Past:\n",
    "            resForms[tense] = parsePastPersonalForms(tmp[1])\n",
    "        else:\n",
    "            resForms[tense] = parsePersonalForms(tmp[1])\n",
    "    return resForms\n",
    "\n",
    "def perfectivityParser(data):\n",
    "    temp = data[1:-1].split('|')\n",
    "    return Perfectivity.convert(temp[0])\n",
    "        \n",
    "def parseVerbRec(splitRec):\n",
    "    res = WordRecord(splitRec[0], {Quantity.Singular: parseVerbForms(splitRec[1]),\n",
    "                                     Quantity.Plural: parseVerbForms(splitRec[2])}, parseTraits(splitRec[3]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePronounRec(splitRec):\n",
    "    return WordRecord(splitRec[0], {Quantity.Singular: parseCases(splitRec[1]),\n",
    "                       Quantity.Plural: parseCases(splitRec[2])}, parseTraits(splitRec[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master parser function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsers = [parseNounRec, parsePronounRec, parseAdjRec, parseVerbRec]\n",
    "partOfSpeechParsers = dict(zip(partsOfSpeech, parsers))\n",
    "\n",
    "def parseRecord(rec):\n",
    "    splitRec = rec.split('\\t')\n",
    "    #try:\n",
    "    partofspeech = PartOfSpeech.convert(splitRec[0])\n",
    "    return (partofspeech, partOfSpeechParsers[partofspeech](splitRec[1:]))\n",
    "    #except KeyError:\n",
    "    #    print('Entry will be skipped')\n",
    "    #return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & parsing phrase structure: words and their traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseRightParts(rightPart):\n",
    "    res = []\n",
    "    for part in rightPart.split('|'):\n",
    "        splitPart = part.split(' ')\n",
    "        curWords = []\n",
    "        for _part in splitPart:\n",
    "            rec = _part.split('-')\n",
    "            traits = []\n",
    "            if len(rec) > 1:\n",
    "                traits = rec[1]\n",
    "            curWords.append(PhraseWordRecord(PartOfSpeech.convert(rec[0]), parseTraits(traits)))\n",
    "        res.append(curWords)\n",
    "    return res\n",
    "\n",
    "def getPhraseStruct(rules):\n",
    "    rulesFinal = {}\n",
    "    for rule in rules:\n",
    "        splitRule = rule.split(':=')\n",
    "        rulesFinal[splitRule[0]] = parseRightParts(splitRule[1])\n",
    "    return rulesFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & parsing non-terminal symbols, denoting overall sentence strucure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSentHeads(rightPart):\n",
    "    res = []\n",
    "    for part in rightPart:\n",
    "        res.append(part)\n",
    "    return res\n",
    "\n",
    "def getSentStruct(rules):\n",
    "    rulesFinal = {startingNT: []}\n",
    "    for rule in rules:\n",
    "        sentHead = rule[1:].split(':=')\n",
    "        for part in sentHead[1].split('|'):\n",
    "            if sentHead[0] in rulesFinal:\n",
    "                rulesFinal[sentHead[0]].append(parseSentHeads(part.split()))\n",
    "            elif sentHead[0] in rulesFinal[startingNT]:\n",
    "                rulesFinal[startingNT][sentHead[0]].append(parseSentHeads(part.split()))\n",
    "            else:\n",
    "                rulesFinal[startingNT][sentHead[0]] = parseSentHeads(part.split())\n",
    "    return rulesFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master parser function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseRules(rulesSet):\n",
    "    sentRules = []\n",
    "    phraseRules = []\n",
    "    for rule in rulesSet:\n",
    "        if len(rule) == 0:\n",
    "            continue\n",
    "        if rule[0] == '!':\n",
    "            sentRules.append(rule)\n",
    "        elif rule[0] != '#':\n",
    "            phraseRules.append(rule)           \n",
    "    return (getSentStruct(sentRules), getPhraseStruct(phraseRules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binding the components together: sentence generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjectiveTraits = [Animate, Gender, Quantity, Case, PhraseHead]\n",
    "#trs = adjectiveTraits & set(word.traits.keys())\n",
    "\n",
    "def caseGetter(word, traits):\n",
    "    res = None\n",
    "    if traits[Case] == Case.Accusative:\n",
    "        if traits[Animate] == Animate.Animate:\n",
    "            if traits[Gender] == Gender.Male:\n",
    "                res = word.data[0]\n",
    "\n",
    "def adjAgreement(phrase):\n",
    "    headTraits = None\n",
    "    if PhraseHead.Head == phrase[0].traits[PhraseHead]:\n",
    "        raise ValueError('Adj can\\'t be head of phrase')\n",
    "    for word in phrase:\n",
    "        if PhraseHead.Head in word.traits:\n",
    "            headTraits = word.traits\n",
    "    res = caseGetter(word, adjectiveTraits & headTraits)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nounTraits = [Animate, Gender, Quantity, Case, PhraseHead]\n",
    "\n",
    "def updateTraits(rule, word):\n",
    "    for tr in nounTraits:\n",
    "        if word.traits[tr] == None:\n",
    "            word.traits[tr] = rule.traits[tr]\n",
    "    \n",
    "def nounForm(rule, word):\n",
    "    updateTraits(rule, word)\n",
    "    if word.traits[Quantity] == None:\n",
    "        word.traits[Quantity] = random.choice(quantities)\n",
    "    if word.traits[Case] == None:\n",
    "            word.traits[Case] = Case.Nominative\n",
    "    return word.data[word.traits[Quantity]][word.traits[Case]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<enum 'Gender'> Gender.Male\n",
    "<enum 'PhraseHead'> None\n",
    "<enum 'Case'> None\n",
    "<enum 'Animate'> Animate.Animate\n",
    "<enum 'Quantity'> Quantity.Plural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nounTraits = [Animate, Gender, Quantity, Case, PhraseHead, Person]\n",
    "\n",
    "def updateTraits(rule, word):\n",
    "    for tr in nounTraits:\n",
    "        if word.traits[tr] == None:\n",
    "            word.traits[tr] = rule.traits[tr]\n",
    "    \n",
    "def nounForm(rule, word):\n",
    "    updateTraits(rule, word)\n",
    "    if word.traits[Quantity] == None:\n",
    "        word.traits[Quantity] = random.choice(quantities)\n",
    "    if word.traits[Case] == None:\n",
    "            word.traits[Case] = Case.Nominative\n",
    "    return word.data[word.traits[Quantity]][word.traits[Case]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement = [nounAgreement]#, parsePronounRec, parseAdjRec, parseVerbRec]\n",
    "agreementSetters = dict(zip(partsOfSpeech, agreement))\n",
    "\n",
    "def traitModifier(traits, word):\n",
    "    return 0\n",
    "\n",
    "def agreementSetter(rule, phrase):\n",
    "    #for word in phrase:\n",
    "    #    if not isinstance(phrase[0], list):\n",
    "    #        #agreementSetters[rule[1].partofspeech](word)\n",
    "            nounForm(rule[1], phrase[1])\n",
    "    \n",
    "#    print('<>>', type(rule))\n",
    "#    print('<>', rule)\n",
    "    #print(phrase)\n",
    "#    agreementSetters[rule.partofspeech(phrase)]\n",
    "#    headTraits = set()\n",
    "#    for elem in rule:\n",
    "#        if PhraseHead.IsHead in elem.traits:\n",
    "#            headTraits = elem.traits\n",
    "#            break\n",
    "    #for i in range(0, headInd):\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordRecord(defaultform='серый', data={<Quantity.Singular: 0>: defaultdict(<enum 'Gender'>, {<Gender.Male: 0>: {<Case.Nominative: 0>: 'серый', <Case.Genitive: 1>: 'серого', <Case.Dative: 2>: 'серому', <Case.Accusative: 3>: {(<Animate.Inanimate: 1>, 'серый'), (<Animate.Animate: 0>, 'серого')}, <Case.Instrumental: 4>: 'серым', <Case.Prepositional: 5>: 'сером'}, <Gender.Female: 1>: {<Case.Nominative: 0>: 'серая', <Case.Genitive: 1>: 'серую', <Case.Dative: 2>: 'серой', <Case.Accusative: 3>: 'серую', <Case.Instrumental: 4>: 'серой', <Case.Prepositional: 5>: 'серой'}}), <Quantity.Plural: 1>: {<Case.Nominative: 0>: 'серые', <Case.Genitive: 1>: 'серых', <Case.Dative: 2>: 'серым', <Case.Accusative: 3>: {(<Animate.Animate: 0>, 'серых'), (<Animate.Inanimate: 1>, 'серые')}, <Case.Instrumental: 4>: 'серыми', <Case.Prepositional: 5>: 'серых'}}, traits={<enum 'Animate'>: None, <enum 'Gender'>: None, <enum 'Tense'>: None, <enum 'Perfectivity'>: None, <enum 'Quantity'>: None, <enum 'Case'>: None, <enum 'PhraseHead'>: None, <enum 'Person'>: None, <enum 'Transitivity'>: None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentGenerator(dct, sentStruct, rules):\n",
    "    pattern = random.choice(sentStruct[startingNT])\n",
    "    base = []\n",
    "    for elem in pattern:\n",
    "        base.append(random.choice(rules[elem]))\n",
    "    sent = []\n",
    "    for phrase in base:\n",
    "        sent.append([])\n",
    "        for _word in phrase:\n",
    "            sent[len(sent)-1].append(random.choice(dct[_word.partofspeech]))\n",
    "    agreementSetter(base[0], sent[0])\n",
    "    #for i in range(0, len(sent)):\n",
    "        #for j in range(0, len(sent[i])):\n",
    "            #print(base[i][j], sent[i][j].defaultform)\n",
    "            #print(agreementSetter(base, sent))\n",
    "    #print(sent)\n",
    "    #print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master \"main\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dctPath = './dictionary.txt', rulesPath = './rules.txt'):\n",
    "    contents = loadFromFile(dctPath)\n",
    "    dct = defaultdict(PartOfSpeech)\n",
    "    for part in partsOfSpeech:\n",
    "        dct[part] = []\n",
    "    for entry in contents:\n",
    "        partOfSpeech, rec = parseRecord(entry)\n",
    "        dct[partOfSpeech].append(rec)\n",
    "    contents = loadFromFile(rulesPath)\n",
    "    sentStruct, rules = parseRules(contents)\n",
    "    sentGenerator(dct, sentStruct, rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "волки\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n"
     ]
    }
   ],
   "source": [
    "print(type(set({'a': 2, 'b': 3}.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
