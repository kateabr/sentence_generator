{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import codecs\n",
    "from collections import namedtuple\n",
    "from enum import Enum\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import random\n",
    "\n",
    "WordRecord = namedtuple(\"WordRecord\", [\"defaultform\", \"data\", \"traits\"])\n",
    "\n",
    "PhraseWordRecord = namedtuple(\"PhraseWordRecord\", [\"partofspeech\", \"traits\"])\n",
    "\n",
    "class Animate(Enum):\n",
    "    Animate = 0\n",
    "    Inanimate = 1\n",
    "    def convert(string: str) -> Animate:\n",
    "        switcher = {\n",
    "            'anim': Animate.Animate,\n",
    "            'nanim': Animate.Inanimate\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Gender(Enum):\n",
    "    Male = 0\n",
    "    Female = 1\n",
    "    Neuter = 2\n",
    "    def convert(string: str) -> Gender:\n",
    "        switcher = {\n",
    "            'M': Gender.Male,\n",
    "            'F': Gender.Female,\n",
    "            'N': Gender.Neuter\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Tense(Enum):\n",
    "    Present = 0\n",
    "    Past = 1\n",
    "    Future = 2\n",
    "    def convert(string: str) -> Gender:\n",
    "        switcher = {\n",
    "            'present': Tense.Present,\n",
    "            'past': Tense.Past,\n",
    "            'future': Tense.Future\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Perfectivity(Enum):\n",
    "    Perfect = 0\n",
    "    Imperfect = 1\n",
    "    def convert(string: str) -> Perfectivity:\n",
    "        switcher = {\n",
    "            'perf': Perfectivity.Perfect,\n",
    "            'imperf': Perfectivity.Imperfect\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class PartOfSpeech(Enum):\n",
    "    Noun = 0\n",
    "    Pronoun = 1\n",
    "    Adjective = 2\n",
    "    Verb = 3\n",
    "    def convert(string: str) -> PartOfSpeech:\n",
    "        switcher = {\n",
    "            'N': PartOfSpeech.Noun,\n",
    "            'Pr': PartOfSpeech.Pronoun,\n",
    "            'Adj': PartOfSpeech.Adjective,\n",
    "            'V': PartOfSpeech.Verb\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Quantity(Enum):\n",
    "    Singular = 0\n",
    "    Plural = 1\n",
    "    def convert(string: str) -> Quantity:\n",
    "        switcher = {\n",
    "            'sing': Quantity.Singular,\n",
    "            'pl': Quantity.Plural\n",
    "        }\n",
    "        return switcher[string]\n",
    "\n",
    "class Case(Enum):\n",
    "    Nominative = 0\n",
    "    Genitive = 1\n",
    "    Dative = 2\n",
    "    Accusative = 3\n",
    "    Instrumental = 4\n",
    "    Prepositional = 5\n",
    "    def convert(string: str) -> Case:\n",
    "        switcher = {\n",
    "            'nom': Case.Nominative,\n",
    "            'gen': Case.Genitive,\n",
    "            'dat': Case.Dative,\n",
    "            'acc': Case.Accusative,\n",
    "            'inst': Case.Instrumental,\n",
    "            'prep': Case.Prepositional\n",
    "        }\n",
    "        return switcher[string]\n",
    "\n",
    "class PhraseHead(Enum):\n",
    "    Head = 0\n",
    "    Slave = 1\n",
    "    def convert(string: str) -> Case:\n",
    "        switcher = {\n",
    "            'head': PhraseHead.Head,\n",
    "            'slave': PhraseHead.Slave\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Person(Enum):\n",
    "    P1 = 0\n",
    "    P2 = 1\n",
    "    P3 = 2\n",
    "    def convert(string: str) -> Person:\n",
    "        switcher = {\n",
    "            '1P': Person.P1,\n",
    "            '2P': Person.P2,\n",
    "            '3P': Person.P3\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "class Transitivity(Enum):\n",
    "    Transitive = 0\n",
    "    Intransitive = 1\n",
    "    def convert(string: str) -> Transitivity:\n",
    "        switcher = {\n",
    "            'tr': Transitivity.Transitive,\n",
    "            'intr': Transitivity.Intransitive\n",
    "        }\n",
    "        return switcher[string]\n",
    "    \n",
    "cases = [Case.Nominative, Case.Genitive, Case.Dative, Case.Accusative, Case.Instrumental,\n",
    "         Case.Prepositional]\n",
    "persons = [Person.P1, Person.P2, Person.P3]\n",
    "genders = [Gender.Male, Gender.Female, Gender.Neuter]\n",
    "wordTraits = [Animate, Gender, Tense, Perfectivity, Quantity, Case, PhraseHead, Person, Transitivity]\n",
    "partsOfSpeech = [PartOfSpeech.Noun, PartOfSpeech.Pronoun, PartOfSpeech.Adjective, PartOfSpeech.Verb]\n",
    "quantities = [Quantity.Singular, Quantity.Plural]\n",
    "perfTenses = [Tense.Past, Tense.Future]\n",
    "imperfTenses = [Tense.Past, Tense.Present]\n",
    "\n",
    "startingNT = \"S\"\n",
    "\n",
    "# imports contents of dictionary and splits it into lines\n",
    "def loadFromFile(path):\n",
    "    with codecs.open(path, 'r', 'utf-8') as dct:\n",
    "        recs = dct.read().splitlines()\n",
    "        return recs\n",
    "    \n",
    "def parseTrait(tr):\n",
    "    for traitType in wordTraits:\n",
    "        try:\n",
    "            return (traitType, traitType.convert(tr))\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "def parseTraits(trs):\n",
    "    res = dict(zip(wordTraits, [None] * len(wordTraits)))\n",
    "    if len(trs) > 2:\n",
    "        for trait in trs[1:-1].split(';'):\n",
    "            trType, val = parseTrait(trait)\n",
    "            res[trType] = val\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple case parser\n",
    "def parseCases(caseString):\n",
    "    splitStr = caseString[1:-1].split('|')\n",
    "    if len(splitStr) == 1:\n",
    "        return []\n",
    "    if len(splitStr) < 6:\n",
    "        raise ValueError(\"Invalid case data\", splitStr)\n",
    "    return dict(zip(cases, splitStr))\n",
    "\n",
    "# noun parser\n",
    "def parseNounRec(splitRec):\n",
    "    try:\n",
    "        return WordRecord(splitRec[0], {Quantity.Singular: parseCases(splitRec[1]),\n",
    "                              Quantity.Plural: parseCases(splitRec[2])}, parseTraits(splitRec[3]))\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Failed to import entry:\", splitRec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case parser for male/plural forms of adjectives (with respect to animacy)\n",
    "def parseAnimCases(caseString):\n",
    "    temp = caseString[1:-1].split('|')\n",
    "    temp[3] = temp[3].split(';')\n",
    "    resDict = dict(zip(cases, temp))\n",
    "    resDict[Case.Accusative] = {(Animate.Animate, temp[3][0]), (Animate.Inanimate, temp[3][1])}\n",
    "    return resDict\n",
    "\n",
    "# case parser for adjectives (with respect to genders)\n",
    "def parseAdjSingCases(caseString):\n",
    "    gens = caseString[1:-1].split(' ')\n",
    "    resCases = defaultdict(Gender)\n",
    "    for caseStringGen in gens:\n",
    "        tmp = caseStringGen.split(':')\n",
    "        gend = Gender.convert(tmp[0])\n",
    "        if gend == Gender.Male:\n",
    "            resCases[gend] = parseAnimCases(tmp[1])\n",
    "        else:\n",
    "            resCases[gend] = parseCases(tmp[1])\n",
    "    return resCases\n",
    "\n",
    "# adjective parser\n",
    "def parseAdjRec(splitRec):\n",
    "    return WordRecord(splitRec[0], {Quantity.Singular: parseAdjSingCases(splitRec[1]),\n",
    "                       Quantity.Plural: parseAnimCases(splitRec[2])}, parseTraits(splitRec[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePastPersonalForms(formString):\n",
    "    temp = formString[1:-1].split('|')\n",
    "    if len(temp) == 3:\n",
    "        return dict(zip(genders, temp))\n",
    "    else:\n",
    "        return temp[0]\n",
    "\n",
    "def parsePersonalForms(formString):\n",
    "    temp = formString[1:-1].split('|')\n",
    "    return dict(zip(persons, temp))\n",
    "\n",
    "def parseVerbForms(formString):\n",
    "    tenses = formString[1:-1].split(' ')\n",
    "    resForms = defaultdict(Tense)\n",
    "    for formString in tenses:\n",
    "        tmp = formString.split(':')\n",
    "        tense = Tense.convert(tmp[0])\n",
    "        if tense == Tense.Past:\n",
    "            resForms[tense] = parsePastPersonalForms(tmp[1])\n",
    "        else:\n",
    "            resForms[tense] = parsePersonalForms(tmp[1])\n",
    "    return resForms\n",
    "\n",
    "def perfectivityParser(data):\n",
    "    temp = data[1:-1].split('|')\n",
    "    return Perfectivity.convert(temp[0])\n",
    "        \n",
    "def parseVerbRec(splitRec):\n",
    "    res = WordRecord(splitRec[0], {Quantity.Singular: parseVerbForms(splitRec[1]),\n",
    "                                     Quantity.Plural: parseVerbForms(splitRec[2])}, parseTraits(splitRec[3]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePronounRec(splitRec):\n",
    "    return WordRecord(splitRec[0], {Quantity.Singular: parseCases(splitRec[1]),\n",
    "                       Quantity.Plural: parseCases(splitRec[2])}, parseTraits(splitRec[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master parser function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsers = [parseNounRec, parsePronounRec, parseAdjRec, parseVerbRec]\n",
    "partOfSpeechParsers = dict(zip(partsOfSpeech, parsers))\n",
    "\n",
    "def parseRecord(rec):\n",
    "    splitRec = rec.split('\\t')\n",
    "    #try:\n",
    "    partofspeech = PartOfSpeech.convert(splitRec[0])\n",
    "    return (partofspeech, partOfSpeechParsers[partofspeech](splitRec[1:]))\n",
    "    #except KeyError:\n",
    "    #    print('Entry will be skipped')\n",
    "    #return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & parsing phrase structure: words and their traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseRightParts(rightPart):\n",
    "    res = []\n",
    "    for part in rightPart.split('|'):\n",
    "        splitPart = part.split(' ')\n",
    "        curWords = []\n",
    "        for _part in splitPart:\n",
    "            rec = _part.split('-')\n",
    "            traits = []\n",
    "            if len(rec) > 1:\n",
    "                traits = rec[1]\n",
    "            curWords.append(PhraseWordRecord(PartOfSpeech.convert(rec[0]), parseTraits(traits)))\n",
    "        res.append(curWords)\n",
    "    return res\n",
    "\n",
    "def getPhraseStruct(rules):\n",
    "    rulesFinal = {}\n",
    "    for rule in rules:\n",
    "        splitRule = rule.split(':=')\n",
    "        rulesFinal[splitRule[0]] = parseRightParts(splitRule[1])\n",
    "    return rulesFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & parsing non-terminal symbols, denoting overall sentence strucure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSentHeads(rightPart):\n",
    "    res = []\n",
    "    for part in rightPart:\n",
    "        res.append(part)\n",
    "    return res\n",
    "\n",
    "def getSentStruct(rules):\n",
    "    rulesFinal = {startingNT: []}\n",
    "    for rule in rules:\n",
    "        sentHead = rule[1:].split(':=')\n",
    "        for part in sentHead[1].split('|'):\n",
    "            if sentHead[0] in rulesFinal:\n",
    "                rulesFinal[sentHead[0]].append(parseSentHeads(part.split()))\n",
    "            elif sentHead[0] in rulesFinal[startingNT]:\n",
    "                rulesFinal[startingNT][sentHead[0]].append(parseSentHeads(part.split()))\n",
    "            else:\n",
    "                rulesFinal[startingNT][sentHead[0]] = parseSentHeads(part.split())\n",
    "    return rulesFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master parser function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseRules(rulesSet):\n",
    "    sentRules = []\n",
    "    phraseRules = []\n",
    "    for rule in rulesSet:\n",
    "        if len(rule) == 0:\n",
    "            continue\n",
    "        if rule[0] == '!':\n",
    "            sentRules.append(rule)\n",
    "        elif rule[0] != '#':\n",
    "            phraseRules.append(rule)           \n",
    "    return (getSentStruct(sentRules), getPhraseStruct(phraseRules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binding the components together: sentence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nounTraits = [Animate, Gender, Quantity, Case, PhraseHead]\n",
    "pronounTraits = [Gender, Quantity, Case, PhraseHead, Person]\n",
    "adjectiveTraits = [Animate, Gender, Quantity, Case, PhraseHead]\n",
    "verbTraits = [Gender, Tense, Perfectivity, Quantity, PhraseHead, Person, Transitivity]\n",
    "posTraits = dict(zip(partsOfSpeech, [nounTraits, pronounTraits, adjectiveTraits, verbTraits]))\n",
    "\n",
    "def updateTraits(src, trg):\n",
    "    for tr in posTraits[src.partofspeech]:\n",
    "        if trg.traits[tr] == None:\n",
    "            trg.traits[tr] = src.traits[tr]\n",
    "            \n",
    "def updateFromHeadTraits(src, trg, trgType):\n",
    "    for tr in posTraits[trgType]:\n",
    "        if trg.traits[tr] == None:\n",
    "            trg.traits[tr] = src[tr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trs = adjectiveTraits & set(word.traits.keys())\n",
    "\n",
    "def adjHead():\n",
    "    return 0\n",
    "\n",
    "def adjAgreement(rule, word, headTr):\n",
    "    updateTraits(rule, word)\n",
    "    updateFromHeadTraits(headTr, word, PartOfSpeech.Adjective)\n",
    "    if word.traits[Case] == Case.Accusative:\n",
    "        if word.traits[Quantity] == Quantity.Plural:\n",
    "            return word.data[word.traits[Quantity]][word.traits[Case]][word.traits[Animate]]\n",
    "        elif word.traits[Gender] == Gender.Male:\n",
    "            return word.data[word.traits[Quantity]][word.traits[Gender]][word.traits[Case]][word.traits[Animate]]\n",
    "    else:\n",
    "        if word.traits[Quantity] == Quantity.Plural:\n",
    "            return word.data[word.traits[Quantity]][word.traits[Case]]\n",
    "        else:\n",
    "            return word.data[word.traits[Quantity]][word.traits[Gender]][word.traits[Case]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traits={<enum 'Animate'>: <Animate.Animate: 0>, <enum 'Gender'>: <Gender.Male: 0>, <enum 'Tense'>: None, <enum 'Perfectivity'>: None, <enum 'Quantity'>: <Quantity.Plural: 1>, <enum 'Case'>: <Case.Nominative: 0>, <enum 'PhraseHead'>: <PhraseHead.Slave: 1>, <enum 'Person'>: None, <enum 'Transitivity'>: None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbAgreement():\n",
    "    return 0\n",
    "\n",
    "def verbHead(rule, word, lingeringAgreement):\n",
    "    if lingeringAgreement != None:\n",
    "        updateTraits(rule, word)\n",
    "        updateFromHeadTraits(lingeringAgreement, word, PartOfSpeech.Verb)\n",
    "        if word.traits[Tense] == None:\n",
    "            if word.traits[Perfectivity] == Perfectivity.Perfect:\n",
    "                word.traits[Tense] = random.choice(perfTenses)\n",
    "            else:\n",
    "                word.traits[Tense] = random.choice(imperfTenses)\n",
    "        w = None\n",
    "        if word.traits[Tense] == Tense.Past:\n",
    "            if (word.traits[Quantity] == Quantity.Singular):\n",
    "                w = word.data[word.traits[Quantity]][word.traits[Tense]][word.traits[Gender]]\n",
    "            else:\n",
    "                w = word.data[word.traits[Quantity]][word.traits[Tense]]\n",
    "        else:\n",
    "            w = word.data[word.traits[Quantity]][word.traits[Tense]][word.traits[Person]]\n",
    "        return (getHeadTraits(word), w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data={<Quantity.Singular: 0>: defaultdict(<enum 'Tense'>, {<Tense.Future: 2>: {<Person.P1: 0>: 'увижу', <Person.P2: 1>: 'увидишь', <Person.P3: 2>: 'увидит'}, <Tense.Past: 1>: {<Gender.Male: 0>: 'увидел', <Gender.Female: 1>: 'увидела', <Gender.Neuter: 2>: 'увидел'}}), <Quantity.Plural: 1>: defaultdict(<enum 'Tense'>, {<Tense.Future: 2>: {<Person.P1: 0>: 'увидим', <Person.P2: 1>: 'увидите', <Person.P3: 2>: 'увидит'}, <Tense.Past: 1>: 'увидели'})}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHeadTraits(word):\n",
    "    res = {}\n",
    "    for tr in nounTraits:\n",
    "        res[tr] = word.traits[tr]\n",
    "    return res\n",
    "            \n",
    "def nounHead(rule, word, lingeringAgreement):\n",
    "    if lingeringAgreement == None:\n",
    "        updateTraits(rule, word)\n",
    "        if word.traits[Quantity] == None:\n",
    "            word.traits[Quantity] = random.choice(quantities)\n",
    "        if word.traits[Case] == None:\n",
    "            word.traits[Case] = Case.Nominative\n",
    "        return (getHeadTraits(word), word.data[word.traits[Quantity]][word.traits[Case]])\n",
    "\n",
    "# not used yet\n",
    "def nounAgreement():\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used yet\n",
    "def pronounAgreement():\n",
    "    return 0\n",
    "\n",
    "def pronounHead():\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement = [nounAgreement, pronounAgreement, adjAgreement, verbAgreement]\n",
    "heads = [nounHead, pronounHead, adjHead, verbHead]\n",
    "agreementSetters = dict(zip(partsOfSpeech, agreement))\n",
    "headAgreementSetters = dict(zip(partsOfSpeech, heads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructLingeringAgreement(headTraits, partOfSpeech):\n",
    "    res = dict(zip(wordTraits, [None] * len(wordTraits)))\n",
    "    for tr, trval in headTraits.items():\n",
    "        res[tr] = trval\n",
    "    if partOfSpeech == PartOfSpeech.Noun:\n",
    "        res[Person] = Person.P3\n",
    "    return res\n",
    "\n",
    "def agreementSetter(rules, phrase, lingeringAgreement = None):\n",
    "    headInd = 0\n",
    "    for i in range(0, len(rules)):\n",
    "        if rules[i].traits[PhraseHead] == PhraseHead.Head:\n",
    "            headInd = i\n",
    "    \n",
    "    headTraits, head = headAgreementSetters[rules[headInd].partofspeech](rules[headInd], phrase[headInd], lingeringAgreement)\n",
    "    \n",
    "    finalPhrase = [None] * len(rules)\n",
    "    finalPhrase[headInd] = head\n",
    "    \n",
    "    for i in range(0, len(rules)):\n",
    "        if i == headInd:\n",
    "            continue\n",
    "        if rules[i].traits[PhraseHead] == PhraseHead.Slave:\n",
    "            finalPhrase[i] = agreementSetters[rules[i].partofspeech](rules[i], phrase[i], headTraits)\n",
    "    \n",
    "    return (finalPhrase, constructLingeringAgreement(headTraits, rules[headInd].partofspeech))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{<enum 'Animate'>: <Animate.Animate: 0>, <enum 'Gender'>: <Gender.Male: 0>, <enum 'Quantity'>: <Quantity.Singular: 0>, <enum 'Case'>: <Case.Nominative: 0>, <enum 'PhraseHead'>: <PhraseHead.Head: 0>}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentGenerator(dct, sentStruct, rules):\n",
    "    pattern = random.choice(sentStruct[startingNT])\n",
    "    base = []\n",
    "    for elem in pattern:\n",
    "        base.append(random.choice(rules[elem]))\n",
    "    sent = []\n",
    "    for phrase in base:\n",
    "        sent.append([])\n",
    "        #print(phrase)\n",
    "        for _word in phrase:\n",
    "            sent[len(sent)-1].append(random.choice(dct[_word.partofspeech]))\n",
    "    #print(sent)\n",
    "    lingeringAgreement = None\n",
    "    finalSentence = []\n",
    "    for i in range(0, 2):\n",
    "        sentPart, lingeringAgreement = agreementSetter(base[i], sent[i], lingeringAgreement)\n",
    "        finalSentence = finalSentence + sentPart\n",
    "    return finalSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master \"main\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dctPath = './dictionary.txt', rulesPath = './rules.txt'):\n",
    "    contents = loadFromFile(dctPath)\n",
    "    dct = defaultdict(PartOfSpeech)\n",
    "    for part in partsOfSpeech:\n",
    "        dct[part] = []\n",
    "    for entry in contents:\n",
    "        partOfSpeech, rec = parseRecord(entry)\n",
    "        dct[partOfSpeech].append(rec)\n",
    "    contents = loadFromFile(rulesPath)\n",
    "    sentStruct, rules = parseRules(contents)\n",
    "    print(sentGenerator(dct, sentStruct, rules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['серый', 'волк', 'увидит']\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
