{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import codecs\n",
    "from collections import namedtuple\n",
    "from enum import Enum\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "WordRecord = namedtuple(\"WordRecord\", [\"defaultform\", \"partofspeech\", \"data\"])\n",
    "NounDataRecord = namedtuple(\"NounDataRecord\", [\"anim\", \"gender\", \"cases\"])\n",
    "VerbDataRecord = namedtuple(\"VerbDataRecord\", [\"perf\", \"quantity\"])\n",
    "\n",
    "PhraseWordRecord = namedtuple(\"PhraseWordRecord\", [\"word\", \"traits\"])\n",
    "\n",
    "class Animate(Enum):\n",
    "    Animate = 0\n",
    "    Inanimate = 1\n",
    "    def convert(string: str) -> Animate:\n",
    "        animSwitcher = {\n",
    "            'anim': Animate.Animate,\n",
    "            'nanim': Animate.Inanimate\n",
    "        }\n",
    "        return animSwitcher.get(string)\n",
    "    \n",
    "class Gender(Enum):\n",
    "    Male = 0\n",
    "    Female = 1\n",
    "    Neuter = 2\n",
    "    def convert(string: str) -> Gender:\n",
    "        genSwitcher = {\n",
    "            'M': Gender.Male,\n",
    "            'F': Gender.Female,\n",
    "            'N': Gender.Neuter\n",
    "        }\n",
    "        return genSwitcher.get(string)\n",
    "    \n",
    "class Tense(Enum):\n",
    "    Present = 0\n",
    "    Past = 1\n",
    "    Future = 2\n",
    "    def convert(string: str) -> Gender:\n",
    "        tenseSwitcher = {\n",
    "            'present': Tense.Present,\n",
    "            'past': Tense.Past,\n",
    "            'future': Tense.Future\n",
    "        }\n",
    "        return tenseSwitcher.get(string)\n",
    "    \n",
    "class Perfectivity(Enum):\n",
    "    Perfect = 0\n",
    "    Imperfect = 1\n",
    "    def convert(string: str) -> Perfectivity:\n",
    "        perfSwitcher = {\n",
    "            'perf': Perfectivity.Perfect,\n",
    "            'imperf': Perfectivity.Imperfect\n",
    "        }\n",
    "        return perfSwitcher.get(string)\n",
    "    \n",
    "class PartOfSpeech(Enum):\n",
    "    Noun = 0\n",
    "    Pronoun = 1\n",
    "    Adjective = 2\n",
    "    Verb = 3\n",
    "    def convert(string: str) -> PartOfSpeech:\n",
    "        posSwitcher = {\n",
    "            'N': PartOfSpeech.Noun,\n",
    "            'Pr': PartOfSpeech.Pronoun,\n",
    "            'Adj': PartOfSpeech.Adjective,\n",
    "            'V': PartOfSpeech.Verb\n",
    "        }\n",
    "        return posSwitcher.get(string)\n",
    "    \n",
    "class Phrase(Enum):\n",
    "    SNP = 0\n",
    "    VP = 1\n",
    "    ONP = 2\n",
    "    NP = 3\n",
    "    S = 4\n",
    "    def convert(string: str) -> Phrase:\n",
    "        phraseSwitcher = {\n",
    "            'SNP': Phrase.SNP,\n",
    "            'VP': Phrase.VP,\n",
    "            'ONP': Phrase.ONP,\n",
    "            'NP': Phrase.NP,\n",
    "            'S': Phrase.S\n",
    "        }\n",
    "        return phraseSwitcher.get(string)\n",
    "    \n",
    "class Quantity(Enum):\n",
    "    Singular = 0\n",
    "    Plural = 1\n",
    "    def convert(string: str) -> Quantity:\n",
    "        qttSwitcher = {\n",
    "            'sing': Quantity.Singular,\n",
    "            'pl': Quantity.Plural\n",
    "        }\n",
    "        return qttSwitcher.get(string)\n",
    "\n",
    "class Case(Enum):\n",
    "    Nominative = 0\n",
    "    Genitive = 1\n",
    "    Dative = 2\n",
    "    Accusative = 3\n",
    "    Instrumental = 4\n",
    "    Prepositional = 5\n",
    "    def convert(string: str) -> Case:\n",
    "        caseSwitcher = {\n",
    "            'nom': Case.Nominative,\n",
    "            'gen': Case.Genitive,\n",
    "            'dat': Case.Dative,\n",
    "            'acc': Case.Accusative,\n",
    "            'inst': Case.Instrumental,\n",
    "            'prep': Case.Prepositional\n",
    "        }\n",
    "        return caseSwitcher.get(string)\n",
    "\n",
    "class PhraseHead(Enum):\n",
    "    IsHead = 0\n",
    "    def convert(string: str) -> Case:\n",
    "        phSwitcher = {\n",
    "            'head': PhraseHead.IsHead\n",
    "        }\n",
    "        return phSwitcher.get(string)\n",
    "    \n",
    "class Person(Enum):\n",
    "    P1 = 0\n",
    "    P2 = 1\n",
    "    P3 = 2\n",
    "    def convert(string: str) -> Person:\n",
    "        pSwitcher = {\n",
    "            '1P': Person.P1,\n",
    "            '2P': Person.P2,\n",
    "            '3P': Person.P3\n",
    "        }\n",
    "        return pSwitcher.get(string)\n",
    "    \n",
    "class Transitivity(Enum):\n",
    "    Transitive = 0\n",
    "    Intransitive = 1\n",
    "    def convert(string: str) -> Transitivity:\n",
    "        trSwitcher = {\n",
    "            'tr': Transitivity.Transitive,\n",
    "            'intr': Transitivity.Intransitive\n",
    "        }\n",
    "        return trSwitcher.get(string)\n",
    "    \n",
    "cases = [Case.Nominative, Case.Genitive, Case.Dative, Case.Accusative, Case.Instrumental,\n",
    "         Case.Prepositional]\n",
    "persons = [Person.P1, Person.P2, Person.P3]\n",
    "genders = [Gender.Male, Gender.Female, Gender.Neuter]\n",
    "wordTraits = [Animate, Gender, Tense, Perfectivity, Quantity, Case, PhraseHead, Person, Transitivity]\n",
    "\n",
    "# imports contents of dictionary and splits it into lines\n",
    "def loadFromFile(path):\n",
    "    with codecs.open(path, 'r', 'utf-8') as dct:\n",
    "        recs = dct.read().splitlines()\n",
    "        return recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns info about animacy and gender\n",
    "def animGenParser(data):\n",
    "    temp = data[1:-1].split('|')\n",
    "    return (Animate.convert(temp[0]), Gender.convert(temp[1]))\n",
    "\n",
    "# simple case parser\n",
    "def parseCases(caseString):\n",
    "    splitStr = caseString[1:-1].split('|')\n",
    "    if len(splitStr) < 6:\n",
    "        return None\n",
    "    return dict(zip(cases, splitStr))\n",
    "\n",
    "# noun parser\n",
    "def parseNounRec(splitRec):\n",
    "    anim, gen = animGenParser(splitRec[4])\n",
    "    return WordRecord(splitRec[0], PartOfSpeech.Noun, NounDataRecord(anim, gen,\n",
    "                            dict([(Quantity.Singular, parseCases(splitRec[2])),\n",
    "                              (Quantity.Plural, parseCases(splitRec[3]))])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case parser for male forms of adjectives (with respect to animacy)\n",
    "def parseMaleCases(caseString):\n",
    "    temp = caseString[1:-1].split('|')\n",
    "    temp[3] = temp[3].split(';')\n",
    "    resDict = dict(zip(cases, temp))\n",
    "    resDict['acc'] = {(Animate.Animate, temp[3][0]), (Animate.Inanimate, temp[3][1])}\n",
    "    return resDict\n",
    "\n",
    "# case parser for adjectives (with respect to genders)\n",
    "def parseAdjSingCases(caseString):\n",
    "    gens = caseString[1:-1].split(' ')\n",
    "    resCases = defaultdict(Gender)\n",
    "    for caseStringGen in gens:\n",
    "        tmp = caseStringGen.split(':')\n",
    "        gend = Gender.convert(tmp[0])\n",
    "        if gend == Gender.Male:\n",
    "            resCases[gend] = parseMaleCases(tmp[1])\n",
    "        else:\n",
    "            resCases[gend] = parseCases(tmp[1])\n",
    "    return resCases\n",
    "\n",
    "# adjective parser\n",
    "def parseAdjRec(splitRec):\n",
    "    return WordRecord(splitRec[0], PartOfSpeech.Adjective, \n",
    "                      dict([(Quantity.Singular, parseAdjSingCases(splitRec[2])),\n",
    "                       (Quantity.Plural, parseCases(splitRec[3]))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePastPersonalForms(formString):\n",
    "    temp = formString[1:-1].split('|')\n",
    "    if len(temp) == 3:\n",
    "        return dict(zip(genders, temp))\n",
    "    else:\n",
    "        return temp[0]\n",
    "\n",
    "def parsePersonalForms(formString):\n",
    "    temp = formString[1:-1].split('|')\n",
    "    return dict(zip(persons, temp))\n",
    "\n",
    "def parseVerbForms(formString):\n",
    "    tenses = formString[1:-1].split(' ')\n",
    "    resForms = defaultdict(Tense)\n",
    "    for formString in tenses:\n",
    "        tmp = formString.split(':')\n",
    "        tense = Tense.convert(tmp[0])\n",
    "        if tense == Tense.Past:\n",
    "            resForms[tense] = parsePastPersonalForms(tmp[1])\n",
    "        else:\n",
    "            resForms[tense] = parsePersonalForms(tmp[1])\n",
    "    return resForms\n",
    "\n",
    "def perfectivityParser(data):\n",
    "    temp = data[1:-1].split('|')\n",
    "    return Perfectivity.convert(temp[0])\n",
    "        \n",
    "def parseVerbRec(splitRec):\n",
    "    return WordRecord(splitRec[0], PartOfSpeech.Verb,\n",
    "                      VerbDataRecord(perfectivityParser(splitRec[4]), parseVerbForms(splitRec[2]),\n",
    "                                     parseVerbForms(splitRec[3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePronounRec(splitRec):\n",
    "    return WordRecord(splitRec[0], PartOfSpeech.Pronoun,\n",
    "                      {(Quantity.Singular, parseCases(splitRec[2])),\n",
    "                       (Quantity.Plural, parseCases(splitRec[3]))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master parser function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseRecord(rec):\n",
    "    splitRec = rec.split('\\t')\n",
    "    if splitRec[1] == 'N':\n",
    "        return parseNounRec(splitRec)\n",
    "    elif splitRec[1] == 'Adj':\n",
    "        return parseAdjRec(splitRec)\n",
    "    elif splitRec[1] == 'V':\n",
    "        return parseVerbRec(splitRec)\n",
    "    elif splitRec[1] == 'Pr':\n",
    "        return parsePronounRec(splitRec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & parsing phrase structure: words and their traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseTrait(tr):\n",
    "    for traitType in wordTraits:\n",
    "        try:\n",
    "            return traitType.convert(tr)\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "def parseTraits(trs):\n",
    "    res = []\n",
    "    if len(trs) > 0:\n",
    "        for trait in trs[1:-1].split(';'):\n",
    "            res.append(parseTrait(trait))\n",
    "    return res\n",
    "\n",
    "def parseRightParts(rightPart):\n",
    "    res = []\n",
    "    for part in rightPart.split('|'):\n",
    "        splitPart = part.split(' ')\n",
    "        curWords = []\n",
    "        for _part in splitPart:\n",
    "            rec = _part.split('-')\n",
    "            traits = []\n",
    "            if len(rec) > 1:\n",
    "                traits = rec[1]\n",
    "            curWords.append(PhraseWordRecord(PartOfSpeech.convert(rec[0]), parseTraits(traits)))\n",
    "        res.append(curWords)\n",
    "    return res\n",
    "\n",
    "def getPhraseStruct(rules):\n",
    "    rulesFinal = {Phrase.S: {}}\n",
    "    for rule in rules:\n",
    "        splitRule = rule.split(':=')\n",
    "        rulesFinal[Phrase.S][Phrase.convert(splitRule[0])] = parseRightParts(splitRule[1])\n",
    "    return rulesFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & parsing non-terminal symbols, denoting overall sentence strucure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSentHeads(rightPart):\n",
    "    res = []\n",
    "    for part in rightPart:\n",
    "        res.append(Phrase.convert(part))\n",
    "    return res\n",
    "\n",
    "def getSentStruct(rules):\n",
    "    rulesFinal = {Phrase.S: []}\n",
    "    for rule in rules:\n",
    "        sentHead = rule[1:].split(':=')\n",
    "        for part in sentHead[1].split('|'):\n",
    "            if Phrase.convert(sentHead[0]) in rulesFinal:\n",
    "                rulesFinal[Phrase.convert(sentHead[0])].append(parseSentHeads(part.split()))\n",
    "            elif Phrase.convert(sentHead[0]) in rulesFinal[Phrase.S]:\n",
    "                rulesFinal[Phrase.S][Phrase.convert(sentHead[0])].append(parseSentHeads(part.split()))\n",
    "            else:\n",
    "                rulesFinal[Phrase.S][Phrase.convert(sentHead[0])] = parseSentHeads(part.split())\n",
    "    return rulesFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master parser function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseRules(rulesSet):\n",
    "    sentRules = []\n",
    "    phraseRules = []\n",
    "    for rule in rulesSet:\n",
    "        if len(rule) == 0:\n",
    "            continue\n",
    "        if rule[0] == '!':\n",
    "            sentRules.append(rule)\n",
    "        elif rule[0] != '#':\n",
    "            phraseRules.append(rule)           \n",
    "    return (getSentStruct(sentRules), getPhraseStruct(phraseRules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<Phrase.S: 5>: [[<Phrase.SNP: 0>, <Phrase.VP: 1>, <Phrase.ONP: 2>], [<Phrase.ONP: 2>, <Phrase.VP: 1>, <Phrase.SNP: 0>]]}\n",
      "[PhraseWordRecord(word=<PartOfSpeech.Noun: 0>, traits=[<Animate.Animate: 0>, None])]\n",
      "[PhraseWordRecord(word=<PartOfSpeech.Adjective: 2>, traits=[]), PhraseWordRecord(word=<PartOfSpeech.Noun: 0>, traits=[<Animate.Animate: 0>, None, None])]\n",
      "[PhraseWordRecord(word=<PartOfSpeech.Pronoun: 1>, traits=[None])]\n"
     ]
    }
   ],
   "source": [
    "dct = loadFromFile('./rules.txt')\n",
    "sent, rules = parseRules(dct)\n",
    "print(sent)\n",
    "for rule in rules[Phrase.S][Phrase.SNP]:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
